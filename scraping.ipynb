{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display: flex;\">\n",
    "  <div style=\"flex: 33%;\">\n",
    "      <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/43/Emblema_Universidad_de_Sevilla.png\" width=150>\n",
    "  </div>\n",
    "  <div style=\"flex: 66%; margin: 1em; text-align: center;\">\n",
    "\n",
    "<h1> Máster Propio en Data Science y Big Data (IV Edición) </h1>\n",
    "<h2> Arquitecturas y Paradigmas para Ciencia del Dato (APCD) </h2>\n",
    "<h3> Técnicas de obtención de datos </h3>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Instructor\n",
    "<br/>\n",
    "<div style=\"display: flex;\">\n",
    "  <div style=\"flex: 50%;\">\n",
    "      <img src=\"https://www.dropbox.com/s/8u2cy57qpz4yx1y/profile_pic.jpg?raw=1\" width=200/>\n",
    "  </div>\n",
    "  <div style=\"flex: 50%;margin: 1em;\">\n",
    "      <b>Javier de la Rosa</b>, <a href=\"mailto:versae@linhd.uned.es\"><i>versae@linhd.uned.es</i></a>, <a href=\"https://twitter.com/versae\"><i>@versae</i></a>\n",
    "      <br />\n",
    "      <br />\n",
    "      <div style=\"padding-left: 1em;\">\n",
    "      Postdoctoral Researcher en el Proyecto Europeo POSTDATA de la UNED\n",
    "      <br />\n",
    "      PhD, Estudios Hispánicos y Humanidades Digitales, University of Western Ontario, Canada\n",
    "      <br />\n",
    "      Máster en Inteligencia Artificial, Universidad de Sevilla, España\n",
    "      <br />\n",
    "      <br />\n",
    "      Ex-Ingeniero de Investigación en la Stanford University, California\n",
    "      <br />\n",
    "      Ex-Director Técnico del laboratorio de investigación CulturePlex Lab en la University of Western Ontario, Canada\n",
    "      </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Índice\n",
    "\n",
    "1. **Introducción**\n",
    "2. Repositorios\n",
    "3. Scraping\n",
    "4. Extracción de información usando expresiones regulares\n",
    "5. Conclusiones\n",
    "6. Bibliografı́a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducción\n",
    "\n",
    "La recolección de datos es el proceso de recopilación y medición de la información sobre un conjunto de variables especı́ficas.\n",
    "\n",
    "Aquı́ surge una pregunta, ¿necesitamos definir un modelo de datos para recolectar los datos asociados?\n",
    "\n",
    "El primer paso es saber qué se quiere obtener como resultado y qué variables nos harı́an falta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducción\n",
    "\n",
    "Existen infinidad de opciones para recolectar datos dependiendo del proyecto y de la disciplina en la que trabajemos. Hoy en dı́a hay un punto común a todos estos procesos (y cada vez más necesario), es\n",
    "la digitalización de la información.\n",
    "\n",
    "Por dar una definición breve y simple, podrı́amos llamar digitalización al proceso de transformación de información \n",
    "analógica a formato digital. Esto facilita tareas como el almacenamiento, consulta, gestión, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducción\n",
    "\n",
    "Partiendo del ámbito de la ciencia de datos, vamos a ver cuatro tipos de procedimientos en cuanto a recolección u obtención de datos se refiere:\n",
    "- Repositorios\n",
    "- Scraping\n",
    "- Extracción de información usando expresiones regulares\n",
    "- APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Índice\n",
    "\n",
    "1. Introducción\n",
    "2. **Repositorios**\n",
    "3. Scraping\n",
    "4. Extracción de información usando expresiones regulares\n",
    "5. Conclusiones\n",
    "6. Bibliografı́a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repositorios\n",
    "Un repositorio o depósito es un sitio centralizado donde se almacena y mantiene información digital, habitualmente bases de\n",
    "datos o archivos informáticos. Los datos almacenados en un repositorio pueden distribuirse a través de una red informática (Internet) o de un medio fı́sico.\n",
    "\n",
    "Nosotros, principalmente, usaremos los repositorios para dos tareas:\n",
    "- Para almacenar y gestionar el código de nuestro proyecto\n",
    "- Para almacenar, descargar y gestionar los conjuntos de datos con los que trabajamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repositorios\n",
    "\n",
    "Algunas de las caracterı́sticas de los repositorios son:\n",
    "- Pueden ser de acceso público o estar protegidos y necesitar de una autentificación previa\n",
    "- Los repositorios más conocidos son los de carácter académico (investigación) e institucional (datos abiertos)\n",
    "- Los repositorios suelen contar con sistemas de respaldo y mantenimiento preventivo y correctivo (tolerancia a fallos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplos de repositorios de datos\n",
    "- https://www.kaggle.com/\n",
    "- http://www.kdnuggets.com/datasets/index.html\n",
    "- https://archive.ics.uci.edu/ml/datasets.html\n",
    "- https://github.com/caesar0301/awesome-public-datasets\n",
    "- http://sevilla.idesevilla.opendata.arcgis.com/\n",
    "- http://datos.madrid.es/portal/site/egob/\n",
    "- Extra: ¿Sólo de datos? https://www.github.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Índice\n",
    "1. Introducción\n",
    "2. Repositorios\n",
    "3. **Scraping**\n",
    "4. Extracción de información usando expresiones regulares\n",
    "5. Conclusiones\n",
    "6. Bibliografı́a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping\n",
    "\n",
    "Web scraping es una técnica que utiliza programas software para extraer información de sitios web.\n",
    "\n",
    "Usualmente, estos programas simulan la navegación de un humano en Internet ya sea utilizando el protocolo HTTP manualmente, o incrustando un navegador en una aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping\n",
    "\n",
    "Como curiosidad: un concepto muy relacionado con el web scraping es la indexación que se produce en Internet. La indexación se lleva a cabo por programas (llamados spiders o crawlers) que rastrean y navegan automáticamente por toda la web. Esta técnica es la que adoptan la mayorı́a de los motores de búsqueda.\n",
    "\n",
    "Desde nuestro punto de vista, el web scraping se enfoca más en la transformación de datos sin estructura en la web en datos estructurados que pueden ser almacenados y analizados. Un campo en el que esta técnica es muy utilizada es el periodismo de datos (social media)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping\n",
    "\n",
    "Para llevar a cabo técnicas de scraping tenemos que tener en cuenta, esencialmente, dos puntos fundamentales:\n",
    "- Acceso al código HTML de la página (hay muchas formas de conseguir esto)\n",
    "- Un lenguaje de programación para obtener los datos que nos interesan\n",
    "- En nuestro caso, usaremos la consola de desarrollo de Firefox/Google Chrome y Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping - HTML\n",
    "\n",
    "Idealmente, todas las páginas web siguen una estructura bien definida semánticamente. Esto nos permitirı́a extraer datos utilizando reglas como encontrar el elemento `<p>` cuyo id es \"subject\" y devolver el \"texto\" que contiene.\n",
    "\n",
    "En el mundo real, el código HTML de una web no tiene por qué estar bien formado y anotado. Esto significa que necesitaremos estudiar la estructura de una web antes de extraer información de la misma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping - HTML\n",
    "```html\n",
    "<html>\n",
    "<head>\n",
    "<title>Mi web</title>\n",
    "</head>\n",
    "<body>\n",
    "<p id=\"author\">Javier de la Rosa</p>\n",
    "<p id=\"subject\">Ciencia de Datos</p>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping - HTML\n",
    "```html\n",
    "<html>\n",
    "<head>\n",
    "<title>Mi web</title>\n",
    "</head>\n",
    "<body>\n",
    "<p>Javier de la Rosa</p>\n",
    "<p>Ciencia de datos</p>\n",
    "<p>Noviembre 2019</p>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping con Python\n",
    "\n",
    "- [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/), encargada de crear un árbol con los elementos que componen una web y facilitar su acceso\n",
    "- [requests](https://requests.readthedocs.io/en/master/) y [requests-html](https://github.com/psf/requests-html), para facilitar la ejecución de peticiones a servidores desde código Python\n",
    "- [html5lib](https://github.com/html5lib/html5lib-python), para mejorar el tratamiento de los elementos HTML\n",
    "```bash\n",
    "$ pip install beautifulsoup4\n",
    "$ pip install requests requests-html\n",
    "$ pip install html5lib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://elpais.com/politica/2019/11/14/actualidad/1573759607_849802.html\">Iglesias advierte a la militancia de que deberá “ceder en muchas cosas”</a>,\n",
       " <a href=\"https://elpais.com/ccaa/2019/11/14/catalunya/1573756832_928724.html\">Una encuesta avalada por la Generalitat pregunta a los estudiantes de secundaria si son independentistas</a>,\n",
       " <a href=\"https://elpais.com/politica/2019/11/14/actualidad/1573754706_551928.html\">El Rey culmina su visita a La Habana con una reunión sorpresa con Raúl Castro</a>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "# elpais.com example - First part\n",
    "# Look at the terms and the robots.txt file\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://elpais.com/\"\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "links = []\n",
    "all_news_lines = soup.select('.articulo-titulo')\n",
    "for line in all_news_lines:\n",
    "    link = line.find('a')\n",
    "    links.append(link)\n",
    "links[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iglesias advierte a la militancia de que deberá “ceder en muchas cosas”',\n",
       " 'Una encuesta avalada por la Generalitat pregunta a los estudiantes de secundaria si son independentistas',\n",
       " 'El Rey culmina su visita a La Habana con una reunión sorpresa con Raúl Castro',\n",
       " 'El juez sospecha que el Govern usó subvenciones para sufragar el ‘procés’',\n",
       " 'Díaz Ayuso replica con ironía a Monasterio sobre el aborto: “Dios no me hizo perfecta y por eso no soy de Vox”']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "# elpais.com example - Second part\n",
    "# Look at the terms and the robots.txt file\n",
    "news = []\n",
    "for link in links:\n",
    "    new = link.text  # link.get(\"title\")\n",
    "    news.append(new)\n",
    "news[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "# Marca example - First Part\n",
    "# Look at the terms and the robots.txt file\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"http://www.marca.com/futbol/primera/calendario.html\"\n",
    "soup = BeautifulSoup(requests.get(url).text, \"html5lib\")\n",
    "jornadas = soup.find_all(\"div\", \"jornada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Jornada 38', <tr>\n",
       " <td class=\"local\">\n",
       " <figure>\n",
       " <img alt=\"Leganés\" src=\"https://e00-marca.uecdn.es/assets/sports/logos/football/png/72x72/957.png\"/>\n",
       " </figure>\n",
       " <span class=\"equipo_t957\">Leganés</span>\n",
       " </td>\n",
       " <td class=\"resultado\"><span class=\"fecha\">24/05</span> <span class=\"hora\">18:30</span></td>\n",
       " <td class=\"visitante\">\n",
       " <span class=\"equipo_t186\">Real Madrid</span>\n",
       " <figure>\n",
       " <img alt=\"Real Madrid\" src=\"https://e00-marca.uecdn.es/assets/sports/logos/football/png/72x72/186.png\"/>\n",
       " </figure>\n",
       " </td>\n",
       " </tr>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "# Marca example - Second Part\n",
    "# Look at the terms and the robots.txt file\n",
    "for jornada in jornadas:\n",
    "    nombre_jornada = jornada.find(\"caption\").text\n",
    "    partidos_jornada = jornada.find_all(\"tr\")\n",
    "nombre_jornada, partidos_jornada[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Villarreal', '24/05 18:30', 'Eibar')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "# Marca example - Third Part\n",
    "# Look at the terms and the robots.txt file\n",
    "for partido_jornada in partidos_jornada[1:]:\n",
    "    local = visitante = resultado = \"\"\n",
    "    try:\n",
    "        local = partido_jornada.find(\"td\", \"local\").text.strip()\n",
    "        visitante = partido_jornada.find(\"td\", \"visitante\").text.strip()\n",
    "        resultado = partido_jornada.find(\"td\", \"resultado\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "local, resultado, visitante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Villarreal vs Eibar: 24/05 18:30 | Jornada 38']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "# Marca example - Fourth Part\n",
    "# Look at the terms and the robots.txt file\n",
    "resultados = []\n",
    "if \"Villarreal\" in [local, visitante]:\n",
    "    partido = u\"{0} vs {1}: {2} | {3}\".format(\n",
    "        local, visitante, resultado, nombre_jornada)\n",
    "resultados.append(partido)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Villarreal vs Granada: 4-4 | Jornada 1',\n",
       " 'Levante vs Villarreal: 2-1 | Jornada 2',\n",
       " 'Villarreal vs Real Madrid: 2-2 | Jornada 3',\n",
       " 'Leganés vs Villarreal: 0-3 | Jornada 4',\n",
       " 'Villarreal vs Valladolid: 2-0 | Jornada 5',\n",
       " 'Barcelona vs Villarreal: 2-1 | Jornada 6',\n",
       " 'Villarreal vs Betis: 5-1 | Jornada 7',\n",
       " 'Osasuna vs Villarreal: 2-1 | Jornada 8',\n",
       " 'Espanyol vs Villarreal: 0-1 | Jornada 9',\n",
       " 'Villarreal vs Alavés: 4-1 | Jornada 10',\n",
       " 'Eibar vs Villarreal: 2-1 | Jornada 11',\n",
       " 'Villarreal vs Athletic: 0-0 | Jornada 12',\n",
       " 'Mallorca vs Villarreal: 3-1 | Jornada 13',\n",
       " 'Villarreal vs Celta: 24/11 18:30 | Jornada 14',\n",
       " 'Valencia vs Villarreal: 30/11 21:00 | Jornada 15',\n",
       " 'Villarreal vs Atlético: 06/12 22:00 | Jornada 16',\n",
       " 'Sevilla vs Villarreal: 15/12 18:30 | Jornada 17',\n",
       " 'Villarreal vs Getafe: 21/12 18:30 | Jornada 18',\n",
       " 'R. Sociedad vs Villarreal: 05/01 14:00 | Jornada 19',\n",
       " 'Villarreal vs Espanyol: 19/01 18:30 | Jornada 20',\n",
       " 'Alavés vs Villarreal: 26/01 18:30 | Jornada 21',\n",
       " 'Villarreal vs Osasuna: 02/02 18:30 | Jornada 22',\n",
       " 'Valladolid vs Villarreal: 09/02 18:30 | Jornada 23',\n",
       " 'Villarreal vs Levante: 16/02 18:30 | Jornada 24',\n",
       " 'Atlético vs Villarreal: 23/02 18:30 | Jornada 25',\n",
       " 'Athletic vs Villarreal: 01/03 18:30 | Jornada 26',\n",
       " 'Villarreal vs Leganés: 08/03 18:30 | Jornada 27',\n",
       " 'Celta vs Villarreal: 15/03 18:30 | Jornada 28',\n",
       " 'Villarreal vs Mallorca: 22/03 18:30 | Jornada 29',\n",
       " 'Granada vs Villarreal: 05/04 18:30 | Jornada 30',\n",
       " 'Villarreal vs Sevilla: 12/04 18:30 | Jornada 31',\n",
       " 'Villarreal vs Valencia: 22/04 21:00 | Jornada 32',\n",
       " 'Betis vs Villarreal: 26/04 18:30 | Jornada 33',\n",
       " 'Villarreal vs Barcelona: 03/05 18:30 | Jornada 34',\n",
       " 'Getafe vs Villarreal: 10/05 18:30 | Jornada 35',\n",
       " 'Villarreal vs R. Sociedad: 13/05 21:00 | Jornada 36',\n",
       " 'Real Madrid vs Villarreal: 17/05 18:30 | Jornada 37',\n",
       " 'Villarreal vs Eibar: 24/05 18:30 | Jornada 38']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scraping con Python\n",
    "\n",
    "resultados = []\n",
    "url = \"http://www.marca.com/futbol/primera/calendario.html\"\n",
    "equipo = \"Villarreal\"\n",
    "soup = BeautifulSoup(requests.get(url).text, \"html5lib\")\n",
    "jornadas = soup.find_all(\"div\", \"jornada\")\n",
    "for jornada in jornadas:\n",
    "    nombre_jornada = jornada.find(\"caption\").text\n",
    "    partidos_jornada = jornada.find_all(\"tr\")\n",
    "    for partido_jornada in partidos_jornada[1:]:\n",
    "        local = partido_jornada.find(\"td\", \"local\").text.strip()\n",
    "        visitante = partido_jornada.find(\"td\", \"visitante\").text.strip()\n",
    "        resultado = partido_jornada.find(\"td\", \"resultado\").text.strip()\n",
    "        if equipo in [local, visitante]:\n",
    "            partido = u\"{0} vs {1}: {2} | {3}\".format(\n",
    "                local, visitante, resultado, nombre_jornada)\n",
    "            if partido not in resultados:\n",
    "                resultados.append(partido)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scrapping - Problemas\n",
    "- Dificultad a la hora de estudiar la estructura de una página web\n",
    "- Las páginas webs pueden cambiar a lo largo del tiempo\n",
    "- Nuestros programas también necesitan cambiar\n",
    "- Necesitamos revisar las leyes y los derechos de uso de las páginas webs para poder aplicar esta técnica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Índice\n",
    "1. Introducción\n",
    "2. Repositorios\n",
    "3. Scraping\n",
    "4. **Extracción de información usando expresiones regulares**\n",
    "5. Conclusiones\n",
    "6. Bibliografı́a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracción de información usando expresiones regulares\n",
    "\n",
    "Una expresión regular (a menudo llamada también regex) es una secuencia de caracteres que forma un patrón de búsqueda, principalmente utilizada para la búsqueda de patrones en textos u operaciones de sustituciones.\n",
    "\n",
    "Haciendo uso de expresiones regulares sobre texto podremos extraer la información que nos interesa almacenar y/o gestionar.\n",
    "\n",
    "La teorı́a tras las expresiones regulares es compleja y muy amplia. Aquı́ sólo veremos unos ejemplos sencillos para entender el funcionamiento de esta técnica para nuestros objetivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python\n",
    "Seguiremos haciendo uso del lenguaje Python. Estudiaremos las expresiones regulares trabajando sobre una serie de ejemplos.\n",
    "\n",
    "El paquete Python que usaremos es el paquete re. Una búsqueda de una expresión regular tı́pica serı́a:\n",
    "```python\n",
    "match = re.search(pat, str)\n",
    "```\n",
    "donde `pat` serı́a el patrón de la expresión regular y `str` la cadena de texto donde buscar. La búsqueda del patrón devuelve el resultado si lo encuentra o None en otro caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found: el:data\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "\n",
    "import re\n",
    "text = \"nos encanta el:data:science\"\n",
    "match = re.search(r\"el:\\w\\w\\w\\w\", text)\n",
    "if match:\n",
    "    print(\"found:\", match.group())\n",
    "else:\n",
    "    print(\"not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python\n",
    "\n",
    "Patrones básicos que podemos usar:\n",
    "- `a`, `X`, `9`: Caracteres normales buscan la coincidencia de ellos mismos.\n",
    "- `\\w`: Busca la coincidencia de letras, dı́gitos o guión bajo `[a-zA-Z0-9 ]`. `\\W` coincide con cualquier carácter que no sea uno de los anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python\n",
    "\n",
    "Más patrones básicos:\n",
    "- `\\s`: Busca la coincidencia de un único espacio en blanco (space, newline, return, tab, form `[ \\n \\r \\t \\f]`). `\\S` coincide con cualquier carácter que no sea uno de los anteriores.\n",
    "- `\\d`: Busca coincidencias de dı́gitos decimales `[0-9]`.\n",
    "- `\\`: Se usa para asegurar que se busca el carácter que le sigue. Por ejemplo, `\\@` nos asegura que buscarı́amos el carácter `@` en el texto. Se usa también para tratar los caracteres especiales como caracteres normales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python\n",
    "Además de estos patrones, podremos usar una serie de caracteres especiales:\n",
    "- `.`: Coincide con cualquier carácter del texto.\n",
    "- `ˆ`, `$`: Sirven para indicar que la búsqueda del patrón sea al comienzo o al final del texto respectivamente.\n",
    "- `*`, `+`, `?`: Se usan para la repetición de ocurrencias en el texto.\n",
    "- `{}[]()-`: Estos caracteres se usan para la definición de grupos y conjuntos dentro del patrón de búsqueda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='www'>\n",
      "None\n",
      "<re.Match object; span=(0, 3), match='123'>\n",
      "<re.Match object; span=(2, 7), match='pe@ex'>\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"www.example.com\"\n",
    "numbers = \"12345\"\n",
    "mail = \"pepe@example.com\"\n",
    "\n",
    "print(re.search(r\"www\", text))\n",
    "print(re.search(r\"wwwe\", text))\n",
    "print(re.search(r\"\\d\\d\\d\", numbers))\n",
    "print(re.search(r\"\\w\\w@\\w\\w\", mail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python\n",
    "Caracteres para aplicar repetición de elementos:\n",
    "- `+`, buscarı́a 1 o más ocurrencias del patrón a su izquierda. Por ejemplo, `i+` equivale a uno o más caracteres `i`\n",
    "- `*`, buscarı́a 0 o más ocurrencias del patrón a su izquierda\n",
    "- `?`, buscarı́a 0 o 1 ocurrencia del patrón a su izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='www'>\n",
      "<re.Match object; span=(0, 1), match='w'>\n",
      "<re.Match object; span=(0, 2), match='ho'>\n",
      "<re.Match object; span=(3, 10), match='a12345c'>\n",
      "<re.Match object; span=(3, 11), match='a12345 c'>\n",
      "<re.Match object; span=(0, 4), match='pepe'>\n",
      "<re.Match object; span=(0, 4), match='pepe'>\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"www.example.com\"\n",
    "numbers_words = \"hola12345caracola\"\n",
    "numbers_words_spaces = \"hola12345 caracola\"\n",
    "mail = \"pepe@example.com\"\n",
    "\n",
    "print(re.search(r\"w+\", text))\n",
    "print(re.search(r\"w?\", text))\n",
    "print(re.search(r\"\\w\\d*\\w\", numbers_words))\n",
    "print(re.search(r\"\\w\\d+\\w\", numbers_words))\n",
    "print(re.search(r\"\\w\\d+\\s+\\w\", numbers_words_spaces))\n",
    "print(re.search(r\"^p\\w+\", mail))\n",
    "print(re.search(r\"p\\w+\", mail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python\n",
    "Dentro de nuestras expresiones regulares podemos usar corchetes.\n",
    "\n",
    "El uso de corchetes indica un conjunto de caracteres. Por ejemplo, `[abc]` buscarı́a `a`, `b` o `c`.\n",
    "\n",
    "Dentro de los corchetes podemos usar los patrones que hemos visto, como `\\w`, `\\s`, etc. Sólo hay una excepción, el carácter `.` significa un punto y no cualquier carácter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba@mail\n",
      "prueba@mail.com\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"betis prueba@mail.com mas pruebas extras\"\n",
    "match = re.search(r\"\\w+@\\w+\", text)\n",
    "if match:\n",
    "    print(match.group())\n",
    "match = re.search(r\"[\\w.-]+@[\\w.-]+\", text)\n",
    "if match:\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python - Group extraction\n",
    "Una caracterı́stica muy útil cuando trabajamos con expresiones regulares son los grupos. Usar grupos nos permite separar el patrón por partes que luego podemos elegir individualmente.\n",
    "\n",
    "Para conseguir esto, englobamos las partes que nos interesan con paréntesis. Para obtener los valores de los grupos obtenidos, simplemente usamos la función `match.group()`, pasándole como parámetro el ı́ndice grupo que queremos seleccionar. Si no le pasamos ningún valor obtendremos el resultado de todo el patrón (funcionamiento normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba@mail.com\n",
      "prueba\n",
      "mail.com\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"betis prueba@mail.com mas pruebas extras\"\n",
    "match = re.search(\"([\\w.-]+)@([\\w.-]+)\", text)\n",
    "if match:\n",
    "    print(match.group()) ## the whole match\n",
    "    print(match.group(1)) ## the user\n",
    "    print(match.group(2)) ## the host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python - findall\n",
    "El método `re.search()` nos devuelve el primer resultado del patrón buscado sobre un texto. Usando el método `findall()` obtenemos todos los resultados del patrón buscado sobre el texto, devueltos en una lista de resultados.\n",
    "\n",
    "Por ejemplo, si queremos encontrar un patrón en un archivo de texto necesitarı́amos iterar sobre todas las lı́neas e ir buscando el patrón en cada una. Si usamos `findall()` podrı́amos pasar como parámetro el propio archivo completo, dejando que el método haga la búsqueda en todo el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba@mail.com\n",
      "scientist@hostmail.com\n",
      "prueba2@pepemail.com\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"betis prueba@mail.com scientist@hostmail.com mas prueba2@pepemail.com pruebas extras\"\n",
    "emails = re.findall(r\"[\\w\\.-]+@[\\w\\.-]+\", text)\n",
    "for email in emails:\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python - findall\n",
    "Si unimos la forma de trabajar de los grupos con el método `findall()`, en vez de obtener una lista de resultados obtendremos una lista de tuplas.\n",
    "\n",
    "Cada una de las tuplas contendrá los resultados de los grupos (group(1), group(2), etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prueba', 'mail.com'), ('scientist', 'hostmail.com'), ('prueba2', 'pepemail.com')]\n",
      "prueba\n",
      "mail.com\n",
      "scientist\n",
      "hostmail.com\n",
      "prueba2\n",
      "pepemail.com\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"betis prueba@mail.com scientist@hostmail.com mas prueba2@pepemail.com pruebas extras\"\n",
    "tuples = re.findall(r\"([\\w\\.-]+)@([\\w\\.-]+)\", text)\n",
    "print(tuples)\n",
    "for pair in tuples:\n",
    "    print(pair[0])\n",
    "    print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expresiones regulares en Python - Substitution\n",
    "Por último, la función `re.sub(pat, replacement, str)` busca todas las coincidencias del patrón `pat` en la cadena `str` y los reemplaza con el valor de `replacement`.\n",
    "\n",
    "La cadena replacement puede incluir los valores `\\1`, `\\2`, etc. en referencia al texto de `group(1)`, `group(2)`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betis alex@my_mail.com alex@my_mail.com mas alex@my_mail.com pruebas extras\n"
     ]
    }
   ],
   "source": [
    "### Expresiones regulares en Python\n",
    "text = \"betis prueba@mail.com scientist@hostmail.com mas prueba2@pepemail.com pruebas extras\"\n",
    "print(re.sub(r\"([\\w\\.-]+)@([\\w\\.-]+)\", r\"alex@my_mail.com\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Índice\n",
    "1. Introducción\n",
    "2. Repositorios\n",
    "3. Scraping\n",
    "4. **Extracción de información usando expresiones regulares**\n",
    "5. Conclusiones\n",
    "6. Bibliografı́a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusiones\n",
    "\n",
    "En nuestro dı́a a dı́a en proyectos tecnológicos vamos a trabajar con repositorios de datos y de código.\n",
    "\n",
    "El scraping es una técnica muy usada y útil para estructurar dato procedente de la web. Entre los principales campos de aplicación encontramos el periodismo de datos (social media).\n",
    "\n",
    "Entre las dificultades que presenta el scraping destacamos el mantenimiento del código y el tener en cuenta los términos de uso legales.\n",
    "\n",
    "Las expresiones regulares nos permiten extraer información a partir de la aplicación de patrones a un texto dado. Esto facilita la creación de conjuntos de datos con un modelo de datos concreto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Índice\n",
    "1. Introducción\n",
    "2. Repositorios\n",
    "3. Scraping\n",
    "4. Extracción de información usando expresiones regulares\n",
    "5. Conclusiones\n",
    "6. **Bibliografı́a**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bibliografı́a\n",
    "- Data Science from scratch, by Joel Grus, O'reilly, 2015\n",
    "- https://en.wikipedia.org/wiki/Data_collection\n",
    "- https://es.wikipedia.org/wiki/Repositorio\n",
    "- https://es.wikipedia.org/wiki/Web_scraping\n",
    "- https://es.wikipedia.org/wiki/Expresión_regular\n",
    "- https://developers.google.com/edu/python/regular-expressions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "rise": {
   "enable_chalkboard": true,
   "footer": "<div style='width: 50%;display: inline-block;color: white;background-color: black;text-align: right;padding: .5em;font-size: 1.2em;'>Máster Propio en Data Science y Big Data</div><div style='width: 50%;display: inline-block;color: white;background-color: #3333B3;text-align: left;padding: .5em;font-size: 1.2em;'>Arquitecturas y paradigmas para Ciencia del Dato</div></div>",
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
